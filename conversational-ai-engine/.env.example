# Application Configuration
APP_NAME=conversational-ai-engine
APP_VERSION=1.0.0
APP_PORT=8087
APP_HOST=0.0.0.0
ENVIRONMENT=development
DEBUG=true

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_CONSUMER_GROUP=conversational-ai-group
KAFKA_TOPICS=["project-updates", "conversation-events"]

# MCP Server Configuration
MCP_SERVER_URL=http://localhost:8082
MCP_SERVER_TIMEOUT=30

# Backend Service Configuration
BACKEND_SERVICE_URL=http://localhost:8084
BACKEND_API_KEY=
BACKEND_TIMEOUT_CONNECT=10.0
BACKEND_TIMEOUT_READ=30.0

# AI API Keys
# OpenAI API Key - Get from https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API Key - Get from https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# AI Provider Configuration
AI_PROVIDER=openai  # Choose: "openai" or "anthropic"
OPENAI_MODEL=gpt-3.5-turbo
CLAUDE_MODEL=claude-3-sonnet-20240229
TEMPERATURE=0.7
MAX_TOKENS=4096

# Streaming Configuration
ENABLE_STREAMING=true
STREAMING_CHUNK_SIZE=1024

# LangChain Configuration (Optional)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=gigapress-conversational-ai

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# CORS Configuration
CORS_ORIGINS=["http://localhost:8080", "http://localhost:3000"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["*"]
CORS_ALLOW_HEADERS=["*"]