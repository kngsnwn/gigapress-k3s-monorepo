"""
Unified AI Service for handling different AI providers
"""
from typing import Dict, Any, List, Optional, AsyncGenerator
from datetime import datetime
import json
import logging
import asyncio
from abc import ABC, abstractmethod

from config.settings import settings

logger = logging.getLogger(__name__)


class AIProvider(ABC):
    """Abstract base class for AI providers"""
    
    @abstractmethod
    async def generate_response(
        self, 
        messages: List[Dict[str, str]], 
        stream: bool = False
    ) -> AsyncGenerator[str, None] | str:
        """Generate AI response"""
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """Check if provider is available"""
        pass


class OpenAIProvider(AIProvider):
    """OpenAI API provider"""
    
    def __init__(self):
        self.api_key = settings.openai_api_key
        self.model = settings.openai_model
        self.client = None
        
    async def initialize(self):
        """Initialize OpenAI client"""
        if not self.api_key:
            logger.warning("OpenAI API key not provided")
            return
            
        try:
            import openai
            self.client = openai.AsyncOpenAI(api_key=self.api_key)
            logger.info("OpenAI client initialized")
        except ImportError:
            logger.error("OpenAI package not installed. Run: pip install openai")
        except Exception as e:
            logger.error(f"Failed to initialize OpenAI client: {e}")
    
    def is_available(self) -> bool:
        """Check if OpenAI provider is available"""
        return bool(self.api_key and self.client)
    
    async def generate_response(
        self, 
        messages: List[Dict[str, str]], 
        stream: bool = False
    ) -> AsyncGenerator[str, None] | str:
        """Generate response using OpenAI API"""
        if not self.is_available():
            raise RuntimeError("OpenAI provider not available")
        
        try:
            # Convert messages to OpenAI format
            openai_messages = []
            for msg in messages:
                openai_messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            if stream:
                return self._stream_response(openai_messages)
            else:
                return await self._generate_response(openai_messages)
                
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            raise
    
    async def _generate_response(self, messages: List[Dict[str, str]]) -> str:
        """Generate non-streaming response"""
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=settings.temperature,
            max_tokens=settings.max_tokens
        )
        return response.choices[0].message.content
    
    async def _stream_response(self, messages: List[Dict[str, str]]) -> AsyncGenerator[str, None]:
        """Generate streaming response"""
        stream = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=settings.temperature,
            max_tokens=settings.max_tokens,
            stream=True
        )
        
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content


class AnthropicProvider(AIProvider):
    """Anthropic Claude API provider"""
    
    def __init__(self):
        self.api_key = settings.anthropic_api_key
        self.model = settings.claude_model
        self.client = None
        
    async def initialize(self):
        """Initialize Anthropic client"""
        if not self.api_key:
            logger.warning("Anthropic API key not provided")
            return
            
        try:
            import anthropic
            self.client = anthropic.AsyncAnthropic(api_key=self.api_key)
            logger.info("Anthropic client initialized")
        except ImportError:
            logger.error("Anthropic package not installed. Run: pip install anthropic")
        except Exception as e:
            logger.error(f"Failed to initialize Anthropic client: {e}")
    
    def is_available(self) -> bool:
        """Check if Anthropic provider is available"""
        return bool(self.api_key and self.client)
    
    async def generate_response(
        self, 
        messages: List[Dict[str, str]], 
        stream: bool = False
    ) -> AsyncGenerator[str, None] | str:
        """Generate response using Anthropic API"""
        if not self.is_available():
            raise RuntimeError("Anthropic provider not available")
        
        try:
            # Convert messages to Anthropic format
            anthropic_messages = []
            system_message = ""
            
            for msg in messages:
                if msg["role"] == "system":
                    system_message = msg["content"]
                else:
                    anthropic_messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
            
            if stream:
                return self._stream_response(anthropic_messages, system_message)
            else:
                return await self._generate_response(anthropic_messages, system_message)
                
        except Exception as e:
            logger.error(f"Anthropic API error: {e}")
            raise
    
    async def _generate_response(
        self, 
        messages: List[Dict[str, str]], 
        system: str = ""
    ) -> str:
        """Generate non-streaming response"""
        response = await self.client.messages.create(
            model=self.model,
            max_tokens=settings.max_tokens,
            temperature=settings.temperature,
            system=system,
            messages=messages
        )
        return response.content[0].text
    
    async def _stream_response(
        self, 
        messages: List[Dict[str, str]], 
        system: str = ""
    ) -> AsyncGenerator[str, None]:
        """Generate streaming response"""
        async with self.client.messages.stream(
            model=self.model,
            max_tokens=settings.max_tokens,
            temperature=settings.temperature,
            system=system,
            messages=messages
        ) as stream:
            async for text in stream.text_stream:
                yield text


class LocalProvider(AIProvider):
    """Local fallback provider for testing"""
    
    def is_available(self) -> bool:
        return True
    
    async def generate_response(
        self, 
        messages: List[Dict[str, str]], 
        stream: bool = False
    ) -> AsyncGenerator[str, None] | str:
        """Generate mock response"""
        if not messages:
            response = "ì•ˆë…•í•˜ì„¸ìš”! GigaPress AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤. ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ì–´ë“œë¦´ê¹Œìš”?"
        else:
            last_message = messages[-1]["content"]
            response = self._generate_mock_response(last_message)
        
        if stream:
            return self._stream_mock_response(response)
        else:
            return response
    
    def _generate_mock_response(self, user_message: str) -> str:
        """Generate context-aware mock response"""
        user_input = user_message.lower()
        
        if any(keyword in user_input for keyword in ['ì‡¼í•‘ëª°', 'ì´ì»¤ë¨¸ìŠ¤', 'ì˜¨ë¼ì¸ì‡¼í•‘']):
            return """ë„¤, ì‡¼í•‘ëª° í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ðŸ›ï¸

**ì£¼ìš” ê¸°ëŠ¥:**
â€¢ ðŸ“¦ ìƒí’ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ
â€¢ ðŸ›’ ìž¥ë°”êµ¬ë‹ˆ ë° ì£¼ë¬¸ ì²˜ë¦¬
â€¢ ðŸ’³ ê²°ì œ ì‹œìŠ¤í…œ ì—°ë™
â€¢ â­ ë¦¬ë·° ë° í‰ì  ì‹œìŠ¤í…œ
â€¢ ðŸ‘¤ íšŒì› ê´€ë¦¬

**ê¸°ìˆ  ìŠ¤íƒ:**
â€¢ Frontend: React + TypeScript
â€¢ Backend: Spring Boot + JPA
â€¢ Database: PostgreSQL
â€¢ Payment: ì•„ìž„í¬íŠ¸ ì—°ë™

ì‹¤ì œ AI APIë¥¼ ì—°ê²°í•˜ì‹œë©´ ë” ìƒì„¸í•œ ë¶„ì„ê³¼ ì½”ë“œ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
í”„ë¡œì íŠ¸ ìƒì„±ì„ ì‹œìž‘í• ê¹Œìš”?"""

        elif any(keyword in user_input for keyword in ['ì˜ˆì•½', 'íšŒì˜ì‹¤', 'ì˜ˆì•½ê´€ë¦¬']):
            return """íšŒì˜ì‹¤ ì˜ˆì•½ ê´€ë¦¬ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ì–´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ðŸ“…

**í•µì‹¬ ê¸°ëŠ¥:**
â€¢ ðŸ¢ íšŒì˜ì‹¤ í˜„í™© ë° ì‹¤ì‹œê°„ ì˜ˆì•½ í™•ì¸
â€¢ ðŸ“… ìº˜ë¦°ë” ê¸°ë°˜ ì˜ˆì•½ ì‹œìŠ¤í…œ
â€¢ ðŸ‘¥ ì‚¬ìš©ìž ê¶Œí•œ ê´€ë¦¬
â€¢ ðŸ“§ ì˜ˆì•½ í™•ì¸ ì•Œë¦¼
â€¢ ðŸ“Š ì‚¬ìš©ë¥  í†µê³„

**ê¸°ìˆ  ìŠ¤íƒ:**
â€¢ Frontend: React + TypeScript
â€¢ Backend: Spring Boot + WebSocket
â€¢ Database: PostgreSQL
â€¢ Real-time: Socket.io

ì‹¤ì œ AI API í‚¤ë¥¼ ì„¤ì •í•˜ì‹œë©´ ë” ì •í™•í•œ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
ì–´ë–¤ ê·œëª¨ì˜ ì¡°ì§ì„ ëŒ€ìƒìœ¼ë¡œ í•˜ì‹œë‚˜ìš”?"""

        else:
            return f""""{user_message}"ì— ëŒ€í•œ í”„ë¡œì íŠ¸ë¥¼ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤!

**ë¶„ì„ ê²°ê³¼:**
â€¢ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì™„ë£Œ
â€¢ ì í•©í•œ ê¸°ìˆ  ìŠ¤íƒ ê²€í†  ì¤‘
â€¢ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì§„í–‰

**ì œì•ˆ ê¸°ìˆ  ìŠ¤íƒ:**
â€¢ Frontend: React + TypeScript
â€¢ Backend: Spring Boot + JPA
â€¢ Database: PostgreSQL
â€¢ Deployment: Docker + Kubernetes

âš ï¸ í˜„ìž¬ ë¡œì»¬ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤.
ì‹¤ì œ AI API (OpenAI ë˜ëŠ” Anthropic)ë¥¼ ì—°ê²°í•˜ì‹œë©´ ë” ì •í™•í•˜ê³  ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

êµ¬ì²´ì ì¸ ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ì„ ë” ì•Œë ¤ì£¼ì‹œë©´ ë§žì¶¤í˜• ì„¤ê³„ë¥¼ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"""
    
    async def _stream_mock_response(self, response: str) -> AsyncGenerator[str, None]:
        """Stream mock response with typing simulation"""
        words = response.split()
        for i, word in enumerate(words):
            yield word + (" " if i < len(words) - 1 else "")
            await asyncio.sleep(0.05)  # Simulate typing speed


class AIService:
    """Unified AI service that manages different providers"""
    
    def __init__(self):
        self.providers = {
            "openai": OpenAIProvider(),
            "anthropic": AnthropicProvider(),
            "local": LocalProvider()
        }
        self.current_provider = None
        
    async def initialize(self):
        """Initialize AI service and providers"""
        logger.info("Initializing AI service...")
        
        # Initialize all providers
        for provider_name, provider in self.providers.items():
            if provider_name != "local":
                await provider.initialize()
        
        # Select the best available provider
        await self._select_provider()
        
        logger.info(f"AI service initialized with provider: {self.current_provider}")
    
    async def _select_provider(self):
        """Select the best available provider"""
        # Try configured provider first
        preferred_provider = settings.ai_provider
        if preferred_provider in self.providers and self.providers[preferred_provider].is_available():
            self.current_provider = preferred_provider
            return
        
        # Try OpenAI
        if self.providers["openai"].is_available():
            self.current_provider = "openai"
            return
        
        # Try Anthropic
        if self.providers["anthropic"].is_available():
            self.current_provider = "anthropic"
            return
        
        # Fallback to local
        self.current_provider = "local"
        logger.warning("No AI API keys available, using local fallback provider")
    
    def get_system_prompt(self) -> str:
        """Get the system prompt for GigaPress AI Assistant"""
        return """ë‹¹ì‹ ì€ GigaPress AI ê°œë°œ ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤.

ì£¼ìš” ì—­í• :
- ì‚¬ìš©ìžì˜ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë° ì„œë¹„ìŠ¤ ê°œë°œì„ ë„ì™€ì¤ë‹ˆë‹¤
- ì ì ˆí•œ ê¸°ìˆ  ìŠ¤íƒì„ ì œì•ˆí•˜ê³  í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤
- Spring Boot, React, PostgreSQL ë“± ëª¨ë˜ ê¸°ìˆ  ìŠ¤íƒì„ í™œìš©í•œ ì†”ë£¨ì…˜ì„ ì œì•ˆí•©ë‹ˆë‹¤
- ì‹¤ìš©ì ì´ê³  êµ¬í˜„ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤
- ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„, API ì„¤ê³„, ë³´ì•ˆ ê³ ë ¤ì‚¬í•­ì„ í¬í•¨í•©ë‹ˆë‹¤

ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
- ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤
- êµ¬ì²´ì ì¸ ê¸°ìˆ  ìŠ¤íƒê³¼ êµ¬í˜„ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤
- ì‚¬ìš©ìžì˜ ìš”êµ¬ì‚¬í•­ì— ë§žëŠ” ë§žì¶¤í˜• ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ìž…ë‹ˆë‹¤
- ì´ëª¨ì§€ë¥¼ ì ì ˆížˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼í•¨ì„ í‘œí˜„í•©ë‹ˆë‹¤
- ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ clarificationì´ í•„ìš”í•œ ê²½ìš° ì ê·¹ì ìœ¼ë¡œ ë¬¼ì–´ë´…ë‹ˆë‹¤
- ë³´ì•ˆ, í™•ìž¥ì„±, ìœ ì§€ë³´ìˆ˜ì„±ì„ ê³ ë ¤í•œ ì„¤ê³„ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤"""
    
    async def generate_response(
        self,
        user_message: str,
        conversation_history: List[Dict[str, str]] = None,
        stream: bool = False
    ) -> AsyncGenerator[str, None] | str:
        """Generate AI response"""
        if not self.current_provider:
            await self._select_provider()
        
        # Prepare messages
        messages = []
        
        # Add system prompt
        messages.append({
            "role": "system",
            "content": self.get_system_prompt()
        })
        
        # Add conversation history (last 10 messages to manage token usage)
        if conversation_history:
            recent_history = conversation_history[-10:]
            messages.extend(recent_history)
        
        # Add current user message
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        try:
            provider = self.providers[self.current_provider]
            return await provider.generate_response(messages, stream)
        except Exception as e:
            logger.error(f"Error generating response with {self.current_provider}: {e}")
            
            # Fallback to local provider
            if self.current_provider != "local":
                logger.info("Falling back to local provider")
                self.current_provider = "local"
                provider = self.providers["local"]
                return await provider.generate_response(messages, stream)
            else:
                raise
    
    def get_provider_info(self) -> Dict[str, Any]:
        """Get information about current provider"""
        return {
            "current_provider": self.current_provider,
            "available_providers": [
                name for name, provider in self.providers.items() 
                if provider.is_available()
            ],
            "provider_status": {
                name: provider.is_available() 
                for name, provider in self.providers.items()
            }
        }


# Create singleton instance
ai_service = AIService()